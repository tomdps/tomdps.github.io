<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>New Publication Title</title>
  <link href="css/bootstrap.min.css" rel="stylesheet">
  <link rel="stylesheet" href="styles.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@100;400;500;700;900&display=swap" rel="stylesheet">
</head>

<body>
    <main role="main" class="container">
        <header>
            <h1>VIBR: View-Invariant Value Functions for Robust Visual Control</h1>
        </header>
        
        <section id="paper-details">
            <h2>Abstract</h2>
            <p>End-to-end reinforcement learning on images showed significant progress in the recent years. Data-
                based approach leverage data augmentation and domain randomization while representation learn-
                ing methods use auxiliary losses to learn task-relevant features. Yet, reinforcement still struggles
                in visually diverse environments full of distractions and spurious noise. In this work, we tackle the
                problem of robust visual control at its core and present VIBR (View-Invariant Bellman Residuals),
                a method that combines multi-view training and invariant prediction to reduce out-of-distribution
                (OOD) generalization gap for RL based visuomotor control. Our model-free approach improve
                baselines performances without the need of additional representation learning objectives and with
                limited additional computational cost. We show that VIBR outperforms existing methods on com-
                plex visuo-motor control environment with high visual perturbation. Our approach achieves state-of
                the-art results on the Distracting Control Suite benchmark, a challenging benchmark still not solved
                by current methods, where we evaluate the robustness to a number of visual perturbators, as well as
                OOD generalization and extrapolation capabilities.</p>

            <h2>Images</h2>
            <img src="image1.jpg" alt="Description of image 1">
            <img src="image2.jpg" alt="Description of image 2">
            
            <a href="arxiv_link_new" target="_blank">arXiv</a>
            <a href="pdf_link_new" target="_blank">PDF</a>
            <a href="poster_link_new" target="_blank">Poster</a>
        </section>
    </main>

    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="script.js"></script>
</body>

</html>
